{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = {'Inactive': 0,'Active': 1} \n",
    "data = pd.read_csv('labels.csv')\n",
    "data.Labels = [Labels[item] for item in data.Labels] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.columns[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('label_int.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_padel = pd.read_csv('output.csv')\n",
    "df_mordred = pd.read_csv ('mordred2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABCGG</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nBase</th>\n",
       "      <th>SpAbs_A</th>\n",
       "      <th>SpMax_A</th>\n",
       "      <th>SpDiam_A</th>\n",
       "      <th>SpAD_A</th>\n",
       "      <th>SpMAD_A</th>\n",
       "      <th>...</th>\n",
       "      <th>SRW10</th>\n",
       "      <th>TSRW10</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>WPath</th>\n",
       "      <th>WPol</th>\n",
       "      <th>Zagreb1</th>\n",
       "      <th>Zagreb2</th>\n",
       "      <th>mZagreb1</th>\n",
       "      <th>mZagreb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.136972</td>\n",
       "      <td>13.587922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.661799</td>\n",
       "      <td>2.381272</td>\n",
       "      <td>4.762544</td>\n",
       "      <td>28.661799</td>\n",
       "      <td>1.302809</td>\n",
       "      <td>...</td>\n",
       "      <td>9.963123</td>\n",
       "      <td>56.083430</td>\n",
       "      <td>289.146664</td>\n",
       "      <td>7.052358</td>\n",
       "      <td>1120</td>\n",
       "      <td>34</td>\n",
       "      <td>114</td>\n",
       "      <td>133</td>\n",
       "      <td>6.777778</td>\n",
       "      <td>4.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>17.136972</td>\n",
       "      <td>13.587922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.661799</td>\n",
       "      <td>2.381272</td>\n",
       "      <td>4.762544</td>\n",
       "      <td>28.661799</td>\n",
       "      <td>1.302809</td>\n",
       "      <td>...</td>\n",
       "      <td>9.963123</td>\n",
       "      <td>56.083430</td>\n",
       "      <td>309.092042</td>\n",
       "      <td>8.134001</td>\n",
       "      <td>1120</td>\n",
       "      <td>34</td>\n",
       "      <td>114</td>\n",
       "      <td>133</td>\n",
       "      <td>6.777778</td>\n",
       "      <td>4.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>17.096532</td>\n",
       "      <td>13.899748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.675521</td>\n",
       "      <td>2.408688</td>\n",
       "      <td>4.817376</td>\n",
       "      <td>28.675521</td>\n",
       "      <td>1.303433</td>\n",
       "      <td>...</td>\n",
       "      <td>10.002835</td>\n",
       "      <td>56.151678</td>\n",
       "      <td>289.146664</td>\n",
       "      <td>7.052358</td>\n",
       "      <td>1072</td>\n",
       "      <td>35</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>6.777778</td>\n",
       "      <td>4.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>20.143738</td>\n",
       "      <td>16.100592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.157166</td>\n",
       "      <td>2.413221</td>\n",
       "      <td>4.826443</td>\n",
       "      <td>33.157166</td>\n",
       "      <td>1.275276</td>\n",
       "      <td>...</td>\n",
       "      <td>10.145139</td>\n",
       "      <td>60.911449</td>\n",
       "      <td>346.168128</td>\n",
       "      <td>7.211836</td>\n",
       "      <td>1743</td>\n",
       "      <td>41</td>\n",
       "      <td>134</td>\n",
       "      <td>156</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>19.396191</td>\n",
       "      <td>15.714573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.888015</td>\n",
       "      <td>2.414530</td>\n",
       "      <td>4.829061</td>\n",
       "      <td>31.888015</td>\n",
       "      <td>1.275521</td>\n",
       "      <td>...</td>\n",
       "      <td>10.150933</td>\n",
       "      <td>59.835505</td>\n",
       "      <td>334.131742</td>\n",
       "      <td>7.770506</td>\n",
       "      <td>1534</td>\n",
       "      <td>41</td>\n",
       "      <td>130</td>\n",
       "      <td>153</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>17.913028</td>\n",
       "      <td>14.547819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.857981</td>\n",
       "      <td>2.411311</td>\n",
       "      <td>4.822623</td>\n",
       "      <td>29.857981</td>\n",
       "      <td>1.298173</td>\n",
       "      <td>...</td>\n",
       "      <td>10.068621</td>\n",
       "      <td>57.431490</td>\n",
       "      <td>304.157563</td>\n",
       "      <td>7.073432</td>\n",
       "      <td>1210</td>\n",
       "      <td>37</td>\n",
       "      <td>120</td>\n",
       "      <td>141</td>\n",
       "      <td>7.638889</td>\n",
       "      <td>5.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>21.936889</td>\n",
       "      <td>15.882083</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.837378</td>\n",
       "      <td>2.427314</td>\n",
       "      <td>4.854628</td>\n",
       "      <td>37.837378</td>\n",
       "      <td>1.351335</td>\n",
       "      <td>...</td>\n",
       "      <td>10.200736</td>\n",
       "      <td>63.294655</td>\n",
       "      <td>373.227440</td>\n",
       "      <td>6.547850</td>\n",
       "      <td>2342</td>\n",
       "      <td>44</td>\n",
       "      <td>146</td>\n",
       "      <td>171</td>\n",
       "      <td>7.388889</td>\n",
       "      <td>6.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>22.712946</td>\n",
       "      <td>16.758557</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.735915</td>\n",
       "      <td>2.428040</td>\n",
       "      <td>4.856080</td>\n",
       "      <td>38.735915</td>\n",
       "      <td>1.335721</td>\n",
       "      <td>...</td>\n",
       "      <td>10.267610</td>\n",
       "      <td>64.547447</td>\n",
       "      <td>387.243090</td>\n",
       "      <td>6.454052</td>\n",
       "      <td>2534</td>\n",
       "      <td>47</td>\n",
       "      <td>152</td>\n",
       "      <td>179</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>22.712946</td>\n",
       "      <td>16.758557</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.735915</td>\n",
       "      <td>2.428040</td>\n",
       "      <td>4.856080</td>\n",
       "      <td>38.735915</td>\n",
       "      <td>1.335721</td>\n",
       "      <td>...</td>\n",
       "      <td>10.267610</td>\n",
       "      <td>64.547447</td>\n",
       "      <td>387.243090</td>\n",
       "      <td>6.454052</td>\n",
       "      <td>2534</td>\n",
       "      <td>47</td>\n",
       "      <td>152</td>\n",
       "      <td>179</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>24.017769</td>\n",
       "      <td>17.883302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.347048</td>\n",
       "      <td>2.428398</td>\n",
       "      <td>4.856795</td>\n",
       "      <td>41.347048</td>\n",
       "      <td>1.333776</td>\n",
       "      <td>...</td>\n",
       "      <td>10.304911</td>\n",
       "      <td>66.771652</td>\n",
       "      <td>417.253655</td>\n",
       "      <td>6.519588</td>\n",
       "      <td>3006</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>188</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>24.017769</td>\n",
       "      <td>17.883302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.347048</td>\n",
       "      <td>2.428398</td>\n",
       "      <td>4.856795</td>\n",
       "      <td>41.347048</td>\n",
       "      <td>1.333776</td>\n",
       "      <td>...</td>\n",
       "      <td>10.304911</td>\n",
       "      <td>66.771652</td>\n",
       "      <td>416.246378</td>\n",
       "      <td>6.607085</td>\n",
       "      <td>3006</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>188</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>23.351103</td>\n",
       "      <td>16.645009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.273508</td>\n",
       "      <td>2.427356</td>\n",
       "      <td>4.854712</td>\n",
       "      <td>40.273508</td>\n",
       "      <td>1.342450</td>\n",
       "      <td>...</td>\n",
       "      <td>10.272531</td>\n",
       "      <td>65.636418</td>\n",
       "      <td>401.258740</td>\n",
       "      <td>6.369186</td>\n",
       "      <td>2919</td>\n",
       "      <td>48</td>\n",
       "      <td>156</td>\n",
       "      <td>183</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>24.834266</td>\n",
       "      <td>17.618507</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.705065</td>\n",
       "      <td>2.427385</td>\n",
       "      <td>4.854770</td>\n",
       "      <td>42.705065</td>\n",
       "      <td>1.334533</td>\n",
       "      <td>...</td>\n",
       "      <td>10.339514</td>\n",
       "      <td>67.956249</td>\n",
       "      <td>430.248904</td>\n",
       "      <td>6.722639</td>\n",
       "      <td>3560</td>\n",
       "      <td>52</td>\n",
       "      <td>166</td>\n",
       "      <td>195</td>\n",
       "      <td>9.611111</td>\n",
       "      <td>7.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>24.834266</td>\n",
       "      <td>17.964869</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.693337</td>\n",
       "      <td>2.427421</td>\n",
       "      <td>4.854843</td>\n",
       "      <td>42.693337</td>\n",
       "      <td>1.334167</td>\n",
       "      <td>...</td>\n",
       "      <td>10.343064</td>\n",
       "      <td>67.961141</td>\n",
       "      <td>430.248904</td>\n",
       "      <td>6.722639</td>\n",
       "      <td>3472</td>\n",
       "      <td>52</td>\n",
       "      <td>166</td>\n",
       "      <td>195</td>\n",
       "      <td>9.611111</td>\n",
       "      <td>7.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>24.984096</td>\n",
       "      <td>17.498620</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.960997</td>\n",
       "      <td>2.427365</td>\n",
       "      <td>4.854729</td>\n",
       "      <td>41.960997</td>\n",
       "      <td>1.311281</td>\n",
       "      <td>...</td>\n",
       "      <td>10.313973</td>\n",
       "      <td>67.901676</td>\n",
       "      <td>430.248904</td>\n",
       "      <td>6.722639</td>\n",
       "      <td>3587</td>\n",
       "      <td>50</td>\n",
       "      <td>166</td>\n",
       "      <td>193</td>\n",
       "      <td>9.611111</td>\n",
       "      <td>7.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>24.984096</td>\n",
       "      <td>17.844982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.901404</td>\n",
       "      <td>2.427390</td>\n",
       "      <td>4.854780</td>\n",
       "      <td>41.901404</td>\n",
       "      <td>1.309419</td>\n",
       "      <td>...</td>\n",
       "      <td>10.317285</td>\n",
       "      <td>67.906354</td>\n",
       "      <td>430.248904</td>\n",
       "      <td>6.722639</td>\n",
       "      <td>3499</td>\n",
       "      <td>50</td>\n",
       "      <td>166</td>\n",
       "      <td>193</td>\n",
       "      <td>9.611111</td>\n",
       "      <td>7.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>25.691203</td>\n",
       "      <td>18.162184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.510006</td>\n",
       "      <td>2.427385</td>\n",
       "      <td>4.854770</td>\n",
       "      <td>43.510006</td>\n",
       "      <td>1.318485</td>\n",
       "      <td>...</td>\n",
       "      <td>10.322625</td>\n",
       "      <td>68.989274</td>\n",
       "      <td>444.264554</td>\n",
       "      <td>6.630814</td>\n",
       "      <td>3872</td>\n",
       "      <td>51</td>\n",
       "      <td>170</td>\n",
       "      <td>197</td>\n",
       "      <td>9.861111</td>\n",
       "      <td>7.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.460016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>2.427361</td>\n",
       "      <td>4.854721</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>1.329464</td>\n",
       "      <td>...</td>\n",
       "      <td>10.253264</td>\n",
       "      <td>64.517437</td>\n",
       "      <td>407.188468</td>\n",
       "      <td>7.143657</td>\n",
       "      <td>2594</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.322550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.629279</td>\n",
       "      <td>2.427345</td>\n",
       "      <td>4.854691</td>\n",
       "      <td>38.629279</td>\n",
       "      <td>1.332044</td>\n",
       "      <td>...</td>\n",
       "      <td>10.250087</td>\n",
       "      <td>64.512793</td>\n",
       "      <td>407.188468</td>\n",
       "      <td>7.143657</td>\n",
       "      <td>2616</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>23.529442</td>\n",
       "      <td>17.011686</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.813004</td>\n",
       "      <td>2.427424</td>\n",
       "      <td>4.854847</td>\n",
       "      <td>39.813004</td>\n",
       "      <td>1.327100</td>\n",
       "      <td>...</td>\n",
       "      <td>10.316822</td>\n",
       "      <td>65.759076</td>\n",
       "      <td>409.208596</td>\n",
       "      <td>7.179098</td>\n",
       "      <td>2871</td>\n",
       "      <td>49</td>\n",
       "      <td>158</td>\n",
       "      <td>186</td>\n",
       "      <td>9.111111</td>\n",
       "      <td>6.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.322550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.629279</td>\n",
       "      <td>2.427345</td>\n",
       "      <td>4.854691</td>\n",
       "      <td>38.629279</td>\n",
       "      <td>1.332044</td>\n",
       "      <td>...</td>\n",
       "      <td>10.250087</td>\n",
       "      <td>64.512793</td>\n",
       "      <td>391.218018</td>\n",
       "      <td>6.863474</td>\n",
       "      <td>2616</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.460016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>2.427361</td>\n",
       "      <td>4.854721</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>1.329464</td>\n",
       "      <td>...</td>\n",
       "      <td>10.253264</td>\n",
       "      <td>64.517437</td>\n",
       "      <td>391.218018</td>\n",
       "      <td>6.863474</td>\n",
       "      <td>2594</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.460016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>2.427361</td>\n",
       "      <td>4.854721</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>1.329464</td>\n",
       "      <td>...</td>\n",
       "      <td>10.253264</td>\n",
       "      <td>64.517437</td>\n",
       "      <td>392.213267</td>\n",
       "      <td>7.003808</td>\n",
       "      <td>2594</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.460016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>2.427361</td>\n",
       "      <td>4.854721</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>1.329464</td>\n",
       "      <td>...</td>\n",
       "      <td>10.253264</td>\n",
       "      <td>64.517437</td>\n",
       "      <td>392.213267</td>\n",
       "      <td>7.003808</td>\n",
       "      <td>2594</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.460016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>2.427361</td>\n",
       "      <td>4.854721</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>1.329464</td>\n",
       "      <td>...</td>\n",
       "      <td>10.253264</td>\n",
       "      <td>64.517437</td>\n",
       "      <td>392.213267</td>\n",
       "      <td>7.003808</td>\n",
       "      <td>2594</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>22.753386</td>\n",
       "      <td>16.460016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>2.427361</td>\n",
       "      <td>4.854721</td>\n",
       "      <td>38.554461</td>\n",
       "      <td>1.329464</td>\n",
       "      <td>...</td>\n",
       "      <td>10.253264</td>\n",
       "      <td>64.517437</td>\n",
       "      <td>392.213267</td>\n",
       "      <td>7.003808</td>\n",
       "      <td>2594</td>\n",
       "      <td>46</td>\n",
       "      <td>152</td>\n",
       "      <td>178</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>21.936889</td>\n",
       "      <td>15.882083</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.837378</td>\n",
       "      <td>2.427314</td>\n",
       "      <td>4.854628</td>\n",
       "      <td>37.837378</td>\n",
       "      <td>1.351335</td>\n",
       "      <td>...</td>\n",
       "      <td>10.200736</td>\n",
       "      <td>63.294655</td>\n",
       "      <td>374.222689</td>\n",
       "      <td>6.682548</td>\n",
       "      <td>2342</td>\n",
       "      <td>44</td>\n",
       "      <td>146</td>\n",
       "      <td>171</td>\n",
       "      <td>7.388889</td>\n",
       "      <td>6.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>21.936889</td>\n",
       "      <td>15.882083</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.837378</td>\n",
       "      <td>2.427314</td>\n",
       "      <td>4.854628</td>\n",
       "      <td>37.837378</td>\n",
       "      <td>1.351335</td>\n",
       "      <td>...</td>\n",
       "      <td>10.200736</td>\n",
       "      <td>63.294655</td>\n",
       "      <td>374.222689</td>\n",
       "      <td>6.682548</td>\n",
       "      <td>2342</td>\n",
       "      <td>44</td>\n",
       "      <td>146</td>\n",
       "      <td>171</td>\n",
       "      <td>7.388889</td>\n",
       "      <td>6.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>23.351103</td>\n",
       "      <td>16.874326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.260120</td>\n",
       "      <td>2.427377</td>\n",
       "      <td>4.854753</td>\n",
       "      <td>40.260120</td>\n",
       "      <td>1.342004</td>\n",
       "      <td>...</td>\n",
       "      <td>10.275982</td>\n",
       "      <td>65.641303</td>\n",
       "      <td>404.233254</td>\n",
       "      <td>6.737221</td>\n",
       "      <td>2875</td>\n",
       "      <td>48</td>\n",
       "      <td>156</td>\n",
       "      <td>183</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>23.460493</td>\n",
       "      <td>16.628460</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.961274</td>\n",
       "      <td>2.427172</td>\n",
       "      <td>4.854344</td>\n",
       "      <td>39.961274</td>\n",
       "      <td>1.332042</td>\n",
       "      <td>...</td>\n",
       "      <td>10.258606</td>\n",
       "      <td>65.607041</td>\n",
       "      <td>421.204118</td>\n",
       "      <td>7.020069</td>\n",
       "      <td>2961</td>\n",
       "      <td>47</td>\n",
       "      <td>156</td>\n",
       "      <td>182</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>6.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>7.806684</td>\n",
       "      <td>7.343579</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.098358</td>\n",
       "      <td>2.369838</td>\n",
       "      <td>4.633950</td>\n",
       "      <td>13.098358</td>\n",
       "      <td>1.309836</td>\n",
       "      <td>...</td>\n",
       "      <td>9.161465</td>\n",
       "      <td>53.745115</td>\n",
       "      <td>156.045870</td>\n",
       "      <td>8.669215</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>61</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>8.623181</td>\n",
       "      <td>8.086503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13.878163</td>\n",
       "      <td>2.396777</td>\n",
       "      <td>4.704140</td>\n",
       "      <td>13.878163</td>\n",
       "      <td>1.261651</td>\n",
       "      <td>...</td>\n",
       "      <td>9.317849</td>\n",
       "      <td>55.364239</td>\n",
       "      <td>171.056769</td>\n",
       "      <td>8.552838</td>\n",
       "      <td>138</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>68</td>\n",
       "      <td>3.694444</td>\n",
       "      <td>2.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>6.501860</td>\n",
       "      <td>6.859141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.877637</td>\n",
       "      <td>2.314437</td>\n",
       "      <td>4.432053</td>\n",
       "      <td>10.877637</td>\n",
       "      <td>1.208626</td>\n",
       "      <td>...</td>\n",
       "      <td>8.796188</td>\n",
       "      <td>51.711315</td>\n",
       "      <td>125.047678</td>\n",
       "      <td>7.815480</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>2.138889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>17.898106</td>\n",
       "      <td>14.741677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.362507</td>\n",
       "      <td>2.591658</td>\n",
       "      <td>5.152523</td>\n",
       "      <td>28.362507</td>\n",
       "      <td>1.289205</td>\n",
       "      <td>...</td>\n",
       "      <td>10.499049</td>\n",
       "      <td>71.445888</td>\n",
       "      <td>294.125594</td>\n",
       "      <td>7.353140</td>\n",
       "      <td>891</td>\n",
       "      <td>45</td>\n",
       "      <td>130</td>\n",
       "      <td>164</td>\n",
       "      <td>7.812500</td>\n",
       "      <td>4.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>18.446294</td>\n",
       "      <td>15.278801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.122835</td>\n",
       "      <td>2.594970</td>\n",
       "      <td>5.160998</td>\n",
       "      <td>30.122835</td>\n",
       "      <td>1.309688</td>\n",
       "      <td>...</td>\n",
       "      <td>10.533775</td>\n",
       "      <td>72.608429</td>\n",
       "      <td>310.120509</td>\n",
       "      <td>7.563915</td>\n",
       "      <td>1015</td>\n",
       "      <td>48</td>\n",
       "      <td>134</td>\n",
       "      <td>170</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>4.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>19.908288</td>\n",
       "      <td>16.530472</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.561765</td>\n",
       "      <td>2.601965</td>\n",
       "      <td>5.178798</td>\n",
       "      <td>32.561765</td>\n",
       "      <td>1.302471</td>\n",
       "      <td>...</td>\n",
       "      <td>10.610957</td>\n",
       "      <td>74.974487</td>\n",
       "      <td>338.115424</td>\n",
       "      <td>7.863149</td>\n",
       "      <td>1291</td>\n",
       "      <td>53</td>\n",
       "      <td>144</td>\n",
       "      <td>183</td>\n",
       "      <td>9.173611</td>\n",
       "      <td>5.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>17.898106</td>\n",
       "      <td>14.741677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.362507</td>\n",
       "      <td>2.591658</td>\n",
       "      <td>5.152523</td>\n",
       "      <td>28.362507</td>\n",
       "      <td>1.289205</td>\n",
       "      <td>...</td>\n",
       "      <td>10.499049</td>\n",
       "      <td>71.445888</td>\n",
       "      <td>296.141244</td>\n",
       "      <td>7.050982</td>\n",
       "      <td>891</td>\n",
       "      <td>45</td>\n",
       "      <td>130</td>\n",
       "      <td>164</td>\n",
       "      <td>7.812500</td>\n",
       "      <td>4.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>17.003721</td>\n",
       "      <td>13.985605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.743520</td>\n",
       "      <td>2.579394</td>\n",
       "      <td>5.121140</td>\n",
       "      <td>27.743520</td>\n",
       "      <td>1.321120</td>\n",
       "      <td>...</td>\n",
       "      <td>10.381862</td>\n",
       "      <td>70.025807</td>\n",
       "      <td>276.078644</td>\n",
       "      <td>8.366020</td>\n",
       "      <td>789</td>\n",
       "      <td>42</td>\n",
       "      <td>122</td>\n",
       "      <td>154</td>\n",
       "      <td>6.861111</td>\n",
       "      <td>4.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>17.003721</td>\n",
       "      <td>13.985605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.743520</td>\n",
       "      <td>2.579394</td>\n",
       "      <td>5.121140</td>\n",
       "      <td>27.743520</td>\n",
       "      <td>1.321120</td>\n",
       "      <td>...</td>\n",
       "      <td>10.381862</td>\n",
       "      <td>70.025807</td>\n",
       "      <td>278.094294</td>\n",
       "      <td>7.945551</td>\n",
       "      <td>789</td>\n",
       "      <td>42</td>\n",
       "      <td>122</td>\n",
       "      <td>154</td>\n",
       "      <td>6.861111</td>\n",
       "      <td>4.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>16.674162</td>\n",
       "      <td>13.779842</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.162573</td>\n",
       "      <td>2.545185</td>\n",
       "      <td>5.090370</td>\n",
       "      <td>26.162573</td>\n",
       "      <td>1.245837</td>\n",
       "      <td>...</td>\n",
       "      <td>10.347757</td>\n",
       "      <td>55.896612</td>\n",
       "      <td>282.161980</td>\n",
       "      <td>6.561907</td>\n",
       "      <td>820</td>\n",
       "      <td>41</td>\n",
       "      <td>118</td>\n",
       "      <td>145</td>\n",
       "      <td>8.451389</td>\n",
       "      <td>4.402778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>18.143738</td>\n",
       "      <td>14.049981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.288219</td>\n",
       "      <td>2.279412</td>\n",
       "      <td>4.558824</td>\n",
       "      <td>30.288219</td>\n",
       "      <td>1.262009</td>\n",
       "      <td>...</td>\n",
       "      <td>9.772296</td>\n",
       "      <td>57.774004</td>\n",
       "      <td>328.131074</td>\n",
       "      <td>7.457524</td>\n",
       "      <td>1748</td>\n",
       "      <td>32</td>\n",
       "      <td>116</td>\n",
       "      <td>129</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>5.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>18.960235</td>\n",
       "      <td>14.976295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.141122</td>\n",
       "      <td>2.285563</td>\n",
       "      <td>4.571126</td>\n",
       "      <td>31.141122</td>\n",
       "      <td>1.245645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.841240</td>\n",
       "      <td>59.063104</td>\n",
       "      <td>346.141638</td>\n",
       "      <td>7.364716</td>\n",
       "      <td>1884</td>\n",
       "      <td>34</td>\n",
       "      <td>122</td>\n",
       "      <td>136</td>\n",
       "      <td>9.638889</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>18.143738</td>\n",
       "      <td>14.049981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.288219</td>\n",
       "      <td>2.279412</td>\n",
       "      <td>4.558824</td>\n",
       "      <td>30.288219</td>\n",
       "      <td>1.262009</td>\n",
       "      <td>...</td>\n",
       "      <td>9.772296</td>\n",
       "      <td>57.774004</td>\n",
       "      <td>332.162374</td>\n",
       "      <td>6.920049</td>\n",
       "      <td>1748</td>\n",
       "      <td>32</td>\n",
       "      <td>116</td>\n",
       "      <td>129</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>5.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>25.312265</td>\n",
       "      <td>19.305934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.934240</td>\n",
       "      <td>2.359489</td>\n",
       "      <td>4.718978</td>\n",
       "      <td>41.934240</td>\n",
       "      <td>1.270735</td>\n",
       "      <td>...</td>\n",
       "      <td>10.255235</td>\n",
       "      <td>68.792853</td>\n",
       "      <td>464.204633</td>\n",
       "      <td>7.141610</td>\n",
       "      <td>3666</td>\n",
       "      <td>50</td>\n",
       "      <td>166</td>\n",
       "      <td>190</td>\n",
       "      <td>11.972222</td>\n",
       "      <td>7.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>26.686039</td>\n",
       "      <td>20.625161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.411187</td>\n",
       "      <td>2.405844</td>\n",
       "      <td>4.811687</td>\n",
       "      <td>44.411187</td>\n",
       "      <td>1.268891</td>\n",
       "      <td>...</td>\n",
       "      <td>10.352172</td>\n",
       "      <td>71.151724</td>\n",
       "      <td>494.215197</td>\n",
       "      <td>7.162539</td>\n",
       "      <td>4210</td>\n",
       "      <td>55</td>\n",
       "      <td>176</td>\n",
       "      <td>203</td>\n",
       "      <td>13.083333</td>\n",
       "      <td>7.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>18.960235</td>\n",
       "      <td>14.976295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.141122</td>\n",
       "      <td>2.285563</td>\n",
       "      <td>4.571126</td>\n",
       "      <td>31.141122</td>\n",
       "      <td>1.245645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.841240</td>\n",
       "      <td>59.063104</td>\n",
       "      <td>339.087412</td>\n",
       "      <td>8.477185</td>\n",
       "      <td>1884</td>\n",
       "      <td>34</td>\n",
       "      <td>122</td>\n",
       "      <td>136</td>\n",
       "      <td>9.638889</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0</td>\n",
       "      <td>18.960235</td>\n",
       "      <td>14.976295</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.141122</td>\n",
       "      <td>2.285563</td>\n",
       "      <td>4.571126</td>\n",
       "      <td>31.141122</td>\n",
       "      <td>1.245645</td>\n",
       "      <td>...</td>\n",
       "      <td>9.841240</td>\n",
       "      <td>59.063104</td>\n",
       "      <td>343.118712</td>\n",
       "      <td>7.798153</td>\n",
       "      <td>1884</td>\n",
       "      <td>34</td>\n",
       "      <td>122</td>\n",
       "      <td>136</td>\n",
       "      <td>9.638889</td>\n",
       "      <td>5.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>20.155669</td>\n",
       "      <td>15.993992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.709453</td>\n",
       "      <td>2.301776</td>\n",
       "      <td>4.603552</td>\n",
       "      <td>33.709453</td>\n",
       "      <td>1.248498</td>\n",
       "      <td>...</td>\n",
       "      <td>9.918228</td>\n",
       "      <td>61.400500</td>\n",
       "      <td>368.125988</td>\n",
       "      <td>7.832468</td>\n",
       "      <td>2324</td>\n",
       "      <td>38</td>\n",
       "      <td>130</td>\n",
       "      <td>146</td>\n",
       "      <td>10.138889</td>\n",
       "      <td>6.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>25.538890</td>\n",
       "      <td>18.790211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.286773</td>\n",
       "      <td>2.532554</td>\n",
       "      <td>5.065107</td>\n",
       "      <td>39.286773</td>\n",
       "      <td>1.227712</td>\n",
       "      <td>...</td>\n",
       "      <td>10.615481</td>\n",
       "      <td>68.678013</td>\n",
       "      <td>442.199153</td>\n",
       "      <td>7.132244</td>\n",
       "      <td>3051</td>\n",
       "      <td>56</td>\n",
       "      <td>178</td>\n",
       "      <td>211</td>\n",
       "      <td>12.236111</td>\n",
       "      <td>6.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>26.136607</td>\n",
       "      <td>19.180465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.527823</td>\n",
       "      <td>2.532797</td>\n",
       "      <td>5.065594</td>\n",
       "      <td>40.527823</td>\n",
       "      <td>1.228116</td>\n",
       "      <td>...</td>\n",
       "      <td>10.633521</td>\n",
       "      <td>69.781107</td>\n",
       "      <td>456.214803</td>\n",
       "      <td>7.018689</td>\n",
       "      <td>3352</td>\n",
       "      <td>58</td>\n",
       "      <td>182</td>\n",
       "      <td>216</td>\n",
       "      <td>12.486111</td>\n",
       "      <td>6.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>27.510381</td>\n",
       "      <td>20.510546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.965421</td>\n",
       "      <td>2.535142</td>\n",
       "      <td>5.070284</td>\n",
       "      <td>42.965421</td>\n",
       "      <td>1.227583</td>\n",
       "      <td>...</td>\n",
       "      <td>10.702727</td>\n",
       "      <td>72.075240</td>\n",
       "      <td>486.225368</td>\n",
       "      <td>7.046744</td>\n",
       "      <td>3892</td>\n",
       "      <td>63</td>\n",
       "      <td>192</td>\n",
       "      <td>229</td>\n",
       "      <td>13.597222</td>\n",
       "      <td>7.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>27.510381</td>\n",
       "      <td>20.560882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.028716</td>\n",
       "      <td>2.535185</td>\n",
       "      <td>5.070369</td>\n",
       "      <td>43.028716</td>\n",
       "      <td>1.229392</td>\n",
       "      <td>...</td>\n",
       "      <td>10.700702</td>\n",
       "      <td>72.072209</td>\n",
       "      <td>486.225368</td>\n",
       "      <td>7.046744</td>\n",
       "      <td>3870</td>\n",
       "      <td>63</td>\n",
       "      <td>192</td>\n",
       "      <td>229</td>\n",
       "      <td>13.597222</td>\n",
       "      <td>7.472222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>26.872224</td>\n",
       "      <td>20.140302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.933708</td>\n",
       "      <td>2.549962</td>\n",
       "      <td>5.099923</td>\n",
       "      <td>41.933708</td>\n",
       "      <td>1.233344</td>\n",
       "      <td>...</td>\n",
       "      <td>10.698627</td>\n",
       "      <td>71.002954</td>\n",
       "      <td>472.209718</td>\n",
       "      <td>7.154693</td>\n",
       "      <td>3536</td>\n",
       "      <td>62</td>\n",
       "      <td>188</td>\n",
       "      <td>225</td>\n",
       "      <td>13.347222</td>\n",
       "      <td>7.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0</td>\n",
       "      <td>25.259895</td>\n",
       "      <td>19.629751</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.781672</td>\n",
       "      <td>2.523437</td>\n",
       "      <td>5.046874</td>\n",
       "      <td>40.781672</td>\n",
       "      <td>1.235808</td>\n",
       "      <td>...</td>\n",
       "      <td>10.475342</td>\n",
       "      <td>69.254536</td>\n",
       "      <td>453.191877</td>\n",
       "      <td>7.309546</td>\n",
       "      <td>3492</td>\n",
       "      <td>57</td>\n",
       "      <td>170</td>\n",
       "      <td>201</td>\n",
       "      <td>13.194444</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>25.259895</td>\n",
       "      <td>19.536968</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.730943</td>\n",
       "      <td>2.523242</td>\n",
       "      <td>5.046483</td>\n",
       "      <td>40.730943</td>\n",
       "      <td>1.234271</td>\n",
       "      <td>...</td>\n",
       "      <td>10.475060</td>\n",
       "      <td>69.254253</td>\n",
       "      <td>453.191877</td>\n",
       "      <td>7.309546</td>\n",
       "      <td>3516</td>\n",
       "      <td>57</td>\n",
       "      <td>170</td>\n",
       "      <td>201</td>\n",
       "      <td>13.194444</td>\n",
       "      <td>7.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>24.524278</td>\n",
       "      <td>18.716054</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.401086</td>\n",
       "      <td>2.498179</td>\n",
       "      <td>4.996357</td>\n",
       "      <td>39.401086</td>\n",
       "      <td>1.231284</td>\n",
       "      <td>...</td>\n",
       "      <td>10.393570</td>\n",
       "      <td>67.990719</td>\n",
       "      <td>437.196962</td>\n",
       "      <td>7.167163</td>\n",
       "      <td>3297</td>\n",
       "      <td>53</td>\n",
       "      <td>164</td>\n",
       "      <td>192</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>7.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>24.524278</td>\n",
       "      <td>18.623764</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.374653</td>\n",
       "      <td>2.497985</td>\n",
       "      <td>4.995970</td>\n",
       "      <td>39.374653</td>\n",
       "      <td>1.230458</td>\n",
       "      <td>...</td>\n",
       "      <td>10.393263</td>\n",
       "      <td>67.990413</td>\n",
       "      <td>437.196962</td>\n",
       "      <td>7.167163</td>\n",
       "      <td>3320</td>\n",
       "      <td>53</td>\n",
       "      <td>164</td>\n",
       "      <td>192</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>7.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0</td>\n",
       "      <td>23.150505</td>\n",
       "      <td>17.548368</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.923712</td>\n",
       "      <td>2.494928</td>\n",
       "      <td>4.989856</td>\n",
       "      <td>36.923712</td>\n",
       "      <td>1.230790</td>\n",
       "      <td>...</td>\n",
       "      <td>10.306784</td>\n",
       "      <td>65.630453</td>\n",
       "      <td>407.186397</td>\n",
       "      <td>7.143621</td>\n",
       "      <td>2774</td>\n",
       "      <td>48</td>\n",
       "      <td>154</td>\n",
       "      <td>179</td>\n",
       "      <td>11.222222</td>\n",
       "      <td>6.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>23.926561</td>\n",
       "      <td>18.237217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.133640</td>\n",
       "      <td>2.497423</td>\n",
       "      <td>4.994847</td>\n",
       "      <td>38.133640</td>\n",
       "      <td>1.230117</td>\n",
       "      <td>...</td>\n",
       "      <td>10.370267</td>\n",
       "      <td>66.870459</td>\n",
       "      <td>423.181312</td>\n",
       "      <td>7.296230</td>\n",
       "      <td>3020</td>\n",
       "      <td>51</td>\n",
       "      <td>160</td>\n",
       "      <td>187</td>\n",
       "      <td>12.083333</td>\n",
       "      <td>6.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>25.898052</td>\n",
       "      <td>19.997202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41.875689</td>\n",
       "      <td>2.503232</td>\n",
       "      <td>5.006464</td>\n",
       "      <td>41.875689</td>\n",
       "      <td>1.231638</td>\n",
       "      <td>...</td>\n",
       "      <td>10.477936</td>\n",
       "      <td>70.332092</td>\n",
       "      <td>467.207527</td>\n",
       "      <td>7.187808</td>\n",
       "      <td>3840</td>\n",
       "      <td>58</td>\n",
       "      <td>174</td>\n",
       "      <td>205</td>\n",
       "      <td>13.444444</td>\n",
       "      <td>7.638889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 1330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    labels        ABC      ABCGG  nAcid  nBase    SpAbs_A   SpMax_A  SpDiam_A  \\\n",
       "0        0  17.136972  13.587922      0      0  28.661799  2.381272  4.762544   \n",
       "1        0  17.136972  13.587922      0      0  28.661799  2.381272  4.762544   \n",
       "2        1  17.096532  13.899748      0      0  28.675521  2.408688  4.817376   \n",
       "3        1  20.143738  16.100592      0      0  33.157166  2.413221  4.826443   \n",
       "4        0  19.396191  15.714573      0      0  31.888015  2.414530  4.829061   \n",
       "5        1  17.913028  14.547819      0      0  29.857981  2.411311  4.822623   \n",
       "6        1  21.936889  15.882083      0      1  37.837378  2.427314  4.854628   \n",
       "7        0  22.712946  16.758557      0      1  38.735915  2.428040  4.856080   \n",
       "8        0  22.712946  16.758557      0      1  38.735915  2.428040  4.856080   \n",
       "9        0  24.017769  17.883302      0      1  41.347048  2.428398  4.856795   \n",
       "10       1  24.017769  17.883302      0      1  41.347048  2.428398  4.856795   \n",
       "11       1  23.351103  16.645009      0      1  40.273508  2.427356  4.854712   \n",
       "12       1  24.834266  17.618507      0      1  42.705065  2.427385  4.854770   \n",
       "13       1  24.834266  17.964869      0      1  42.693337  2.427421  4.854843   \n",
       "14       1  24.984096  17.498620      0      1  41.960997  2.427365  4.854729   \n",
       "15       1  24.984096  17.844982      0      1  41.901404  2.427390  4.854780   \n",
       "16       0  25.691203  18.162184      0      1  43.510006  2.427385  4.854770   \n",
       "17       0  22.753386  16.460016      0      1  38.554461  2.427361  4.854721   \n",
       "18       1  22.753386  16.322550      0      1  38.629279  2.427345  4.854691   \n",
       "19       0  23.529442  17.011686      0      1  39.813004  2.427424  4.854847   \n",
       "20       1  22.753386  16.322550      0      1  38.629279  2.427345  4.854691   \n",
       "21       1  22.753386  16.460016      0      1  38.554461  2.427361  4.854721   \n",
       "22       0  22.753386  16.460016      0      1  38.554461  2.427361  4.854721   \n",
       "23       1  22.753386  16.460016      0      1  38.554461  2.427361  4.854721   \n",
       "24       0  22.753386  16.460016      0      1  38.554461  2.427361  4.854721   \n",
       "25       0  22.753386  16.460016      0      1  38.554461  2.427361  4.854721   \n",
       "26       0  21.936889  15.882083      0      1  37.837378  2.427314  4.854628   \n",
       "27       0  21.936889  15.882083      0      1  37.837378  2.427314  4.854628   \n",
       "28       1  23.351103  16.874326      0      1  40.260120  2.427377  4.854753   \n",
       "29       1  23.460493  16.628460      0      1  39.961274  2.427172  4.854344   \n",
       "..     ...        ...        ...    ...    ...        ...       ...       ...   \n",
       "60       0   7.806684   7.343579      0      4  13.098358  2.369838  4.633950   \n",
       "61       1   8.623181   8.086503      0      5  13.878163  2.396777  4.704140   \n",
       "62       1   6.501860   6.859141      0      0  10.877637  2.314437  4.432053   \n",
       "63       1  17.898106  14.741677      0      0  28.362507  2.591658  5.152523   \n",
       "64       0  18.446294  15.278801      0      0  30.122835  2.594970  5.160998   \n",
       "65       0  19.908288  16.530472      0      0  32.561765  2.601965  5.178798   \n",
       "66       1  17.898106  14.741677      0      0  28.362507  2.591658  5.152523   \n",
       "67       0  17.003721  13.985605      0      0  27.743520  2.579394  5.121140   \n",
       "68       1  17.003721  13.985605      0      0  27.743520  2.579394  5.121140   \n",
       "69       0  16.674162  13.779842      0      0  26.162573  2.545185  5.090370   \n",
       "70       1  18.143738  14.049981      0      0  30.288219  2.279412  4.558824   \n",
       "71       0  18.960235  14.976295      0      0  31.141122  2.285563  4.571126   \n",
       "72       0  18.143738  14.049981      0      0  30.288219  2.279412  4.558824   \n",
       "73       0  25.312265  19.305934      0      0  41.934240  2.359489  4.718978   \n",
       "74       0  26.686039  20.625161      0      0  44.411187  2.405844  4.811687   \n",
       "75       1  18.960235  14.976295      1      0  31.141122  2.285563  4.571126   \n",
       "76       0  18.960235  14.976295      1      0  31.141122  2.285563  4.571126   \n",
       "77       1  20.155669  15.993992      0      0  33.709453  2.301776  4.603552   \n",
       "78       1  25.538890  18.790211      0      0  39.286773  2.532554  5.065107   \n",
       "79       1  26.136607  19.180465      0      0  40.527823  2.532797  5.065594   \n",
       "80       0  27.510381  20.510546      0      0  42.965421  2.535142  5.070284   \n",
       "81       0  27.510381  20.560882      0      0  43.028716  2.535185  5.070369   \n",
       "82       1  26.872224  20.140302      0      0  41.933708  2.549962  5.099923   \n",
       "83       0  25.259895  19.629751      1      0  40.781672  2.523437  5.046874   \n",
       "84       0  25.259895  19.536968      1      0  40.730943  2.523242  5.046483   \n",
       "85       0  24.524278  18.716054      1      0  39.401086  2.498179  4.996357   \n",
       "86       0  24.524278  18.623764      1      0  39.374653  2.497985  4.995970   \n",
       "87       0  23.150505  17.548368      1      0  36.923712  2.494928  4.989856   \n",
       "88       0  23.926561  18.237217      1      0  38.133640  2.497423  4.994847   \n",
       "89       0  25.898052  19.997202      1      0  41.875689  2.503232  5.006464   \n",
       "\n",
       "       SpAD_A   SpMAD_A    ...         SRW10     TSRW10          MW       AMW  \\\n",
       "0   28.661799  1.302809    ...      9.963123  56.083430  289.146664  7.052358   \n",
       "1   28.661799  1.302809    ...      9.963123  56.083430  309.092042  8.134001   \n",
       "2   28.675521  1.303433    ...     10.002835  56.151678  289.146664  7.052358   \n",
       "3   33.157166  1.275276    ...     10.145139  60.911449  346.168128  7.211836   \n",
       "4   31.888015  1.275521    ...     10.150933  59.835505  334.131742  7.770506   \n",
       "5   29.857981  1.298173    ...     10.068621  57.431490  304.157563  7.073432   \n",
       "6   37.837378  1.351335    ...     10.200736  63.294655  373.227440  6.547850   \n",
       "7   38.735915  1.335721    ...     10.267610  64.547447  387.243090  6.454052   \n",
       "8   38.735915  1.335721    ...     10.267610  64.547447  387.243090  6.454052   \n",
       "9   41.347048  1.333776    ...     10.304911  66.771652  417.253655  6.519588   \n",
       "10  41.347048  1.333776    ...     10.304911  66.771652  416.246378  6.607085   \n",
       "11  40.273508  1.342450    ...     10.272531  65.636418  401.258740  6.369186   \n",
       "12  42.705065  1.334533    ...     10.339514  67.956249  430.248904  6.722639   \n",
       "13  42.693337  1.334167    ...     10.343064  67.961141  430.248904  6.722639   \n",
       "14  41.960997  1.311281    ...     10.313973  67.901676  430.248904  6.722639   \n",
       "15  41.901404  1.309419    ...     10.317285  67.906354  430.248904  6.722639   \n",
       "16  43.510006  1.318485    ...     10.322625  68.989274  444.264554  6.630814   \n",
       "17  38.554461  1.329464    ...     10.253264  64.517437  407.188468  7.143657   \n",
       "18  38.629279  1.332044    ...     10.250087  64.512793  407.188468  7.143657   \n",
       "19  39.813004  1.327100    ...     10.316822  65.759076  409.208596  7.179098   \n",
       "20  38.629279  1.332044    ...     10.250087  64.512793  391.218018  6.863474   \n",
       "21  38.554461  1.329464    ...     10.253264  64.517437  391.218018  6.863474   \n",
       "22  38.554461  1.329464    ...     10.253264  64.517437  392.213267  7.003808   \n",
       "23  38.554461  1.329464    ...     10.253264  64.517437  392.213267  7.003808   \n",
       "24  38.554461  1.329464    ...     10.253264  64.517437  392.213267  7.003808   \n",
       "25  38.554461  1.329464    ...     10.253264  64.517437  392.213267  7.003808   \n",
       "26  37.837378  1.351335    ...     10.200736  63.294655  374.222689  6.682548   \n",
       "27  37.837378  1.351335    ...     10.200736  63.294655  374.222689  6.682548   \n",
       "28  40.260120  1.342004    ...     10.275982  65.641303  404.233254  6.737221   \n",
       "29  39.961274  1.332042    ...     10.258606  65.607041  421.204118  7.020069   \n",
       "..        ...       ...    ...           ...        ...         ...       ...   \n",
       "60  13.098358  1.309836    ...      9.161465  53.745115  156.045870  8.669215   \n",
       "61  13.878163  1.261651    ...      9.317849  55.364239  171.056769  8.552838   \n",
       "62  10.877637  1.208626    ...      8.796188  51.711315  125.047678  7.815480   \n",
       "63  28.362507  1.289205    ...     10.499049  71.445888  294.125594  7.353140   \n",
       "64  30.122835  1.309688    ...     10.533775  72.608429  310.120509  7.563915   \n",
       "65  32.561765  1.302471    ...     10.610957  74.974487  338.115424  7.863149   \n",
       "66  28.362507  1.289205    ...     10.499049  71.445888  296.141244  7.050982   \n",
       "67  27.743520  1.321120    ...     10.381862  70.025807  276.078644  8.366020   \n",
       "68  27.743520  1.321120    ...     10.381862  70.025807  278.094294  7.945551   \n",
       "69  26.162573  1.245837    ...     10.347757  55.896612  282.161980  6.561907   \n",
       "70  30.288219  1.262009    ...      9.772296  57.774004  328.131074  7.457524   \n",
       "71  31.141122  1.245645    ...      9.841240  59.063104  346.141638  7.364716   \n",
       "72  30.288219  1.262009    ...      9.772296  57.774004  332.162374  6.920049   \n",
       "73  41.934240  1.270735    ...     10.255235  68.792853  464.204633  7.141610   \n",
       "74  44.411187  1.268891    ...     10.352172  71.151724  494.215197  7.162539   \n",
       "75  31.141122  1.245645    ...      9.841240  59.063104  339.087412  8.477185   \n",
       "76  31.141122  1.245645    ...      9.841240  59.063104  343.118712  7.798153   \n",
       "77  33.709453  1.248498    ...      9.918228  61.400500  368.125988  7.832468   \n",
       "78  39.286773  1.227712    ...     10.615481  68.678013  442.199153  7.132244   \n",
       "79  40.527823  1.228116    ...     10.633521  69.781107  456.214803  7.018689   \n",
       "80  42.965421  1.227583    ...     10.702727  72.075240  486.225368  7.046744   \n",
       "81  43.028716  1.229392    ...     10.700702  72.072209  486.225368  7.046744   \n",
       "82  41.933708  1.233344    ...     10.698627  71.002954  472.209718  7.154693   \n",
       "83  40.781672  1.235808    ...     10.475342  69.254536  453.191877  7.309546   \n",
       "84  40.730943  1.234271    ...     10.475060  69.254253  453.191877  7.309546   \n",
       "85  39.401086  1.231284    ...     10.393570  67.990719  437.196962  7.167163   \n",
       "86  39.374653  1.230458    ...     10.393263  67.990413  437.196962  7.167163   \n",
       "87  36.923712  1.230790    ...     10.306784  65.630453  407.186397  7.143621   \n",
       "88  38.133640  1.230117    ...     10.370267  66.870459  423.181312  7.296230   \n",
       "89  41.875689  1.231638    ...     10.477936  70.332092  467.207527  7.187808   \n",
       "\n",
       "    WPath  WPol  Zagreb1  Zagreb2   mZagreb1  mZagreb2  \n",
       "0    1120    34      114      133   6.777778  4.861111  \n",
       "1    1120    34      114      133   6.777778  4.861111  \n",
       "2    1072    35      114      134   6.777778  4.888889  \n",
       "3    1743    41      134      156   9.000000  5.722222  \n",
       "4    1534    41      130      153   8.750000  5.500000  \n",
       "5    1210    37      120      141   7.638889  5.055556  \n",
       "6    2342    44      146      171   7.388889  6.222222  \n",
       "7    2534    47      152      179   8.250000  6.416667  \n",
       "8    2534    47      152      179   8.250000  6.416667  \n",
       "9    3006    50      160      188   8.750000  7.000000  \n",
       "10   3006    50      160      188   8.750000  7.000000  \n",
       "11   2919    48      156      183   8.500000  6.722222  \n",
       "12   3560    52      166      195   9.611111  7.166667  \n",
       "13   3472    52      166      195   9.611111  7.166667  \n",
       "14   3587    50      166      193   9.611111  7.055556  \n",
       "15   3499    50      166      193   9.611111  7.055556  \n",
       "16   3872    51      170      197   9.861111  7.305556  \n",
       "17   2594    46      152      178   8.250000  6.388889  \n",
       "18   2616    46      152      178   8.250000  6.388889  \n",
       "19   2871    49      158      186   9.111111  6.583333  \n",
       "20   2616    46      152      178   8.250000  6.388889  \n",
       "21   2594    46      152      178   8.250000  6.388889  \n",
       "22   2594    46      152      178   8.250000  6.388889  \n",
       "23   2594    46      152      178   8.250000  6.388889  \n",
       "24   2594    46      152      178   8.250000  6.388889  \n",
       "25   2594    46      152      178   8.250000  6.388889  \n",
       "26   2342    44      146      171   7.388889  6.222222  \n",
       "27   2342    44      146      171   7.388889  6.222222  \n",
       "28   2875    48      156      183   8.500000  6.722222  \n",
       "29   2961    47      156      182   8.500000  6.638889  \n",
       "..    ...   ...      ...      ...        ...       ...  \n",
       "60    105    12       52       61   2.833333  2.222222  \n",
       "61    138    14       58       68   3.694444  2.388889  \n",
       "62     83    10       42       48   4.083333  2.138889  \n",
       "63    891    45      130      164   7.812500  4.541667  \n",
       "64   1015    48      134      170   8.062500  4.916667  \n",
       "65   1291    53      144      183   9.173611  5.375000  \n",
       "66    891    45      130      164   7.812500  4.541667  \n",
       "67    789    42      122      154   6.861111  4.444444  \n",
       "68    789    42      122      154   6.861111  4.444444  \n",
       "69    820    41      118      145   8.451389  4.402778  \n",
       "70   1748    32      116      129   8.777778  5.388889  \n",
       "71   1884    34      122      136   9.638889  5.555556  \n",
       "72   1748    32      116      129   8.777778  5.388889  \n",
       "73   3666    50      166      190  11.972222  7.305556  \n",
       "74   4210    55      176      203  13.083333  7.833333  \n",
       "75   1884    34      122      136   9.638889  5.555556  \n",
       "76   1884    34      122      136   9.638889  5.555556  \n",
       "77   2324    38      130      146  10.138889  6.222222  \n",
       "78   3051    56      178      211  12.236111  6.611111  \n",
       "79   3352    58      182      216  12.486111  6.944444  \n",
       "80   3892    63      192      229  13.597222  7.472222  \n",
       "81   3870    63      192      229  13.597222  7.472222  \n",
       "82   3536    62      188      225  13.347222  7.166667  \n",
       "83   3492    57      170      201  13.194444  7.333333  \n",
       "84   3516    57      170      201  13.194444  7.333333  \n",
       "85   3297    53      164      192  12.333333  7.111111  \n",
       "86   3320    53      164      192  12.333333  7.111111  \n",
       "87   2774    48      154      179  11.222222  6.583333  \n",
       "88   3020    51      160      187  12.083333  6.777778  \n",
       "89   3840    58      174      205  13.444444  7.638889  \n",
       "\n",
       "[90 rows x 1330 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mordred2 = df_mordred.drop(['name'], axis=1).dropna(axis=1)\n",
    "df_mordred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_mordred2, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv', index=None)\n",
    "test.to_csv('test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "mmscaler = MinMaxScaler()\n",
    "rscaler = RobustScaler()\n",
    "\n",
    "scaler = rscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:]\n",
    "Y_train = train.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.iloc[:, 1:]\n",
    "Y_test = test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train_scale = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 5)\n",
    "principalComponents = pca.fit_transform(X_train.iloc[:,1:])\n",
    "PCA_train = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalComponents = pca.transform(X_test.iloc[:,1:])\n",
    "PCA_test = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.0740740741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "PCA_train_scale = scaler.fit_transform(PCA_train)\n",
    "PCA_test_scale = scaler.transform(PCA_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(PCA_train_scale, Y_train)\n",
    "print(clf.score(PCA_test_scale, Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.740740740741\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(PCA_test_scale)\n",
    "score = accuracy_score(test.iloc[:, 0], y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66849816849816857, 0.53406593406593406, 0.60054945054945053, 0.6018315018315018, 0.60421245421245418, 0.58754578754578757]\n",
      "\n",
      "\n",
      "[0.53864468864468873, 0.61849816849816852, 0.63644688644688652, 0.5567765567765568, 0.63516483516483524, 0.63516483516483524]\n",
      "\n",
      "\n",
      "[0.5849816849816849, 0.58498168498168501, 0.56831501831501829, 0.55402930402930406, 0.57069597069597067, 0.58736263736263739]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pca_component = [5, 10, 15, 20, 25, 30]\n",
    "kernel = ['rbf', 'linear', 'poly']\n",
    "resultsDf = pd.DataFrame()\n",
    "\n",
    "for k in kernel:\n",
    "    temp = []\n",
    "    for c in pca_component:\n",
    "        pca = PCA(n_components = c)\n",
    "\n",
    "        X_train_PCA = pca.fit_transform(X_train)\n",
    "        \n",
    "#         X_val_PCA = pca.transform(X_val)\n",
    "\n",
    "        PCA_train_scale = scaler.fit_transform(X_train_PCA)\n",
    "#         PCA_val_scale = scaler.transform(X_val_PCA)\n",
    "\n",
    "        clf = SVC(kernel=k)\n",
    "        score_ = np.average(cross_val_score(clf, PCA_train_scale, Y_train, cv=5))\n",
    "    \n",
    "#         clf.fit(PCA_train_scale, Y_train)\n",
    "#         CurrentScore = clf.score(PCA_val_scale, Y_val)*100\n",
    "        temp.append(score_)\n",
    "    print(temp)\n",
    "    resultsDf[k] = temp\n",
    "    print(\"\\n\")\n",
    "resultsDf['n'] = pca_component\n",
    "resultsDf = resultsDf.set_index('n', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rbf</th>\n",
       "      <th>linear</th>\n",
       "      <th>poly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.668498</td>\n",
       "      <td>0.538645</td>\n",
       "      <td>0.584982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.534066</td>\n",
       "      <td>0.618498</td>\n",
       "      <td>0.584982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.600549</td>\n",
       "      <td>0.636447</td>\n",
       "      <td>0.568315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.601832</td>\n",
       "      <td>0.556777</td>\n",
       "      <td>0.554029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.604212</td>\n",
       "      <td>0.635165</td>\n",
       "      <td>0.570696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.587546</td>\n",
       "      <td>0.635165</td>\n",
       "      <td>0.587363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rbf    linear      poly\n",
       "n                               \n",
       "5   0.668498  0.538645  0.584982\n",
       "10  0.534066  0.618498  0.584982\n",
       "15  0.600549  0.636447  0.568315\n",
       "20  0.601832  0.556777  0.554029\n",
       "25  0.604212  0.635165  0.570696\n",
       "30  0.587546  0.635165  0.587363"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c33f41cc88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "resultsDf.plot()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('PCA Component Number')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBF = 5, Linear = 15, Poly = 30\n",
    "# Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbf\n",
    "pca = PCA(n_components = 5)\n",
    "\n",
    "rbf_train = pca.fit_transform(X_train)\n",
    "#rbf_test = pca.transform(X_test)\n",
    "\n",
    "rbf_train_scale = scaler.fit_transform(rbf_train)\n",
    "#rbf_test_scale = scaler.transform(rbf_test)\n",
    "\n",
    "#linear\n",
    "pca = PCA(n_components = 15)\n",
    "\n",
    "linear_train = pca.fit_transform(X_train)\n",
    "#linear_test = pca.transform(X_test)\n",
    "\n",
    "linear_train_scale = scaler.fit_transform(linear_train)\n",
    "#linear_test_scale = scaler.transform(linear_test)\n",
    "\n",
    "#poly\n",
    "pca = PCA(n_components = 30)\n",
    "\n",
    "poly_train = pca.fit_transform(X_train)\n",
    "#poly_test = pca.transform(X_test)\n",
    "\n",
    "poly_train_scale = scaler.fit_transform(poly_train)\n",
    "#poly_test_scale = scaler.transform(poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 'scale', 'kernel': 'rbf', 'C': 10}\n",
      "{'kernel': 'linear', 'C': 100}\n",
      "{'gamma': 'auto', 'degree': 3, 'kernel': 'poly', 'C': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_loop = [\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': ['scale', 'auto'], 'kernel': ['rbf']},\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'kernel': ['linear']},\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': ['scale', 'auto'], 'degree': [2, 3, 4, 5],'kernel': ['poly']},\n",
    " ]\n",
    "\n",
    "hasil = {}\n",
    "count = 0\n",
    "for param in param_loop:\n",
    "    if param['kernel']==['linear'] :\n",
    "        data_train = linear_train_scale\n",
    "    elif param['kernel']==['rbf'] :\n",
    "        data_train = rbf_train_scale\n",
    "    elif param['kernel']==['poly'] :\n",
    "        data_train = poly_train_scale\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc, param)\n",
    "    clf.fit(data_train, Y_train,)\n",
    "    print(clf.best_params_)\n",
    "    hasil = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "    hasil.to_csv('hasil{}.csv'.format(count), sep=',', float_format='%.3f')\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.001</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 0.001}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.010</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 0.01}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.100</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 0.1}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.849</td>\n",
       "      <td>1.000</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 1}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.904</td>\n",
       "      <td>10.000</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 10}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.935</td>\n",
       "      <td>100.000</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'kernel': 'linear', 'C': 100}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean_fit_time  mean_score_time  mean_test_score  \\\n",
       "0           0          0.000            0.000            0.587   \n",
       "1           1          0.000            0.000            0.587   \n",
       "2           2          0.001            0.000            0.635   \n",
       "3           3          0.001            0.000            0.619   \n",
       "4           4          0.002            0.001            0.651   \n",
       "5           5          0.003            0.000            0.667   \n",
       "\n",
       "   mean_train_score  param_C param_kernel                            params  \\\n",
       "0             0.587    0.001       linear  {'kernel': 'linear', 'C': 0.001}   \n",
       "1             0.587    0.010       linear   {'kernel': 'linear', 'C': 0.01}   \n",
       "2             0.770    0.100       linear    {'kernel': 'linear', 'C': 0.1}   \n",
       "3             0.849    1.000       linear      {'kernel': 'linear', 'C': 1}   \n",
       "4             0.904   10.000       linear     {'kernel': 'linear', 'C': 10}   \n",
       "5             0.935  100.000       linear    {'kernel': 'linear', 'C': 100}   \n",
       "\n",
       "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0                5              0.591               0.585              0.571   \n",
       "1                5              0.591               0.585              0.571   \n",
       "2                3              0.636               0.756              0.667   \n",
       "3                4              0.636               0.805              0.619   \n",
       "4                2              0.682               0.829              0.571   \n",
       "5                1              0.636               0.829              0.571   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0               0.595                0.6               0.581         0.000   \n",
       "1               0.595                0.6               0.581         0.000   \n",
       "2               0.786                0.6               0.767         0.000   \n",
       "3               0.881                0.6               0.860         0.000   \n",
       "4               0.905                0.7               0.977         0.001   \n",
       "5               0.976                0.8               1.000         0.001   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0             0.0           0.012            0.006  \n",
       "1             0.0           0.012            0.006  \n",
       "2             0.0           0.027            0.012  \n",
       "3             0.0           0.015            0.032  \n",
       "4             0.0           0.057            0.060  \n",
       "5             0.0           0.095            0.076  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil0 = pd.read_csv('hasil0.csv', sep=',')\n",
    "hasil1 = pd.read_csv('hasil1.csv', sep=',')\n",
    "hasil2 = pd.read_csv('hasil2.csv', sep=',')\n",
    "\n",
    "hasil1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function _passthrough_scorer at 0x000001C33D473400>\n"
     ]
    }
   ],
   "source": [
    "print(clf.scorer_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#{'gamma': 'scale', 'C':  , 'kernel': 'rbf'}\n",
    "#{'kernel': 'linear', 'C': 100}\n",
    "#{'degree': 3, 'gamma': 'auto', 'C': 100, 'kernel': 'poly'}\n",
    "\n",
    "#Default => C : 1, gamma : scale, degree : 3\n",
    "#RBF = 5, Linear = 15, Poly = 5\n",
    "\n",
    "untuned_model = [\n",
    "    SVC(kernel='rbf'),\n",
    "    SVC(kernel='linear'),\n",
    "    SVC(kernel='poly')\n",
    "]\n",
    "\n",
    "tuned_model = [\n",
    "    SVC(kernel='rbf', C=10, gamma = 'scale'),\n",
    "    SVC(kernel='linear', C=100),\n",
    "    SVC(kernel='poly', C=100, gamma = 'auto', degree = 3)\n",
    "]\n",
    "\n",
    "validation_untuned = pd.DataFrame(columns=['kernel',\n",
    "                                   'tn',\n",
    "                                   'fp',\n",
    "                                   'fn',\n",
    "                                   'tp',\n",
    "                                   'accuracy',\n",
    "                                   'precision',\n",
    "                                   'recall',\n",
    "                                   'f1'\n",
    "                                  ])\n",
    "validation_tuned = validation_untuned\n",
    "\n",
    "pca_comp = [5, 15, 30]\n",
    "kernelA = ['rbf', 'linear', 'poly']\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "xTrain = train.iloc[:, 1:]\n",
    "yTrain = train.iloc[:, 0]\n",
    "xTest = test.iloc[:, 1:]\n",
    "yTest = test.iloc[:, 0]\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(3):\n",
    "    pca = PCA(n_components = pca_comp[i])\n",
    "    tempTrain = pca.fit_transform(xTrain)\n",
    "    tempTest = pca.transform(xTest)\n",
    "    \n",
    "    tempTrainScaled = scaler.fit_transform(tempTrain)\n",
    "    tempTestScaled = scaler.transform(tempTest)\n",
    "    \n",
    "    utModel = untuned_model[i].fit(tempTrainScaled, yTrain)\n",
    "    yPred = utModel.predict(tempTrainScaled)\n",
    "    \n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(yTrain, yPred).ravel()\n",
    "    \n",
    "    d = {'kernel' : kernelA[i],\n",
    "        'tn' : tn,\n",
    "        'fp' : fp,\n",
    "        'fn' : fn,\n",
    "        'tp' : tp,\n",
    "        'accuracy' : metrics.accuracy_score(yTrain, yPred)*100,\n",
    "        'precision' : metrics.precision_score(yTrain, yPred)*100,\n",
    "        'recall' : metrics.recall_score(yTrain, yPred)*100,\n",
    "        'f1' : metrics.f1_score(yTrain, yPred)*100}\n",
    "    \n",
    "    validation_untuned = validation_untuned.append(d, ignore_index=True)\n",
    "    \n",
    "    tModel = tuned_model[i].fit(tempTrainScaled, yTrain)\n",
    "    yPred = tModel.predict(tempTrainScaled)\n",
    "    \n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(yTrain, yPred).ravel()\n",
    "    \n",
    "    d = {'kernel' : kernelA[i],\n",
    "        'tn' : tn,\n",
    "        'fp' : fp,\n",
    "        'fn' : fn,\n",
    "        'tp' : tp,\n",
    "        'accuracy' : metrics.accuracy_score(yTrain, yPred)*100,\n",
    "        'precision' : metrics.precision_score(yTrain, yPred)*100,\n",
    "        'recall' : metrics.recall_score(yTrain, yPred)*100,\n",
    "        'f1' : metrics.f1_score(yTrain, yPred)*100}\n",
    "    \n",
    "    validation_tuned = validation_tuned.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>80.952381</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>69.230769</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>80.952381</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>69.230769</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>68.253968</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  tn fp  fn  tp   accuracy   precision     recall    f1\n",
       "0     rbf  33  4   8  18  80.952381   81.818182  69.230769  75.0\n",
       "1  linear  33  4   8  18  80.952381   81.818182  69.230769  75.0\n",
       "2    poly  37  0  20   6  68.253968  100.000000  23.076923  37.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_untuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>90.476190</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>89.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>79.365079</td>\n",
       "      <td>80.952381</td>\n",
       "      <td>65.384615</td>\n",
       "      <td>72.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  tn fp fn  tp    accuracy   precision      recall          f1\n",
       "0     rbf  31  6  0  26   90.476190   81.250000  100.000000   89.655172\n",
       "1  linear  33  4  9  17   79.365079   80.952381   65.384615   72.340426\n",
       "2    poly  37  0  0  26  100.000000  100.000000  100.000000  100.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'C': 1, 'kernel': 'linear'}\n",
    "#{'C': 100, 'kernel': 'rbf', 'gamma': 'scale'}\n",
    "#{'C': 100, 'degree': 5, 'kernel': 'poly', 'gamma': 'scale'}\n",
    "\n",
    "#Default => C : 1, gamma : scale, degree : 3\n",
    "#RBF = 5, Linear = 15, Poly = 5\n",
    "\n",
    "untuned_model = [\n",
    "    SVC(kernel='rbf'),\n",
    "    SVC(kernel='linear'),\n",
    "    SVC(kernel='poly')\n",
    "]\n",
    "\n",
    "tuned_model = [\n",
    "    SVC(kernel='rbf', C=10, gamma = 'scale'),\n",
    "    SVC(kernel='linear', C=100),\n",
    "    SVC(kernel='poly', C=100, gamma = 'auto', degree = 3)\n",
    "]\n",
    "\n",
    "train_predict = pd.DataFrame(columns=['kernel',\n",
    "                                   'tn',\n",
    "                                   'fp',\n",
    "                                   'fn',\n",
    "                                   'tp',\n",
    "                                   'accuracy',\n",
    "                                   'precision',\n",
    "                                   'recall',\n",
    "                                   'f1'\n",
    "                                  ])\n",
    "\n",
    "test_predict = train_predict\n",
    "\n",
    "ut_train = train_predict\n",
    "\n",
    "ut_test = train_predict\n",
    "\n",
    "pca_comp = [5, 15, 30]\n",
    "kernelA = ['rbf', 'linear', 'poly']\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "xTrain = train.iloc[:, 1:]\n",
    "yTrain = train.iloc[:, 0]\n",
    "xTest = test.iloc[:, 1:]\n",
    "yTest = test.iloc[:, 0]\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(3):\n",
    "    pca = PCA(n_components = pca_comp[i])\n",
    "    tempTrain = pca.fit_transform(xTrain)\n",
    "    tempTest = pca.transform(xTest)\n",
    "    \n",
    "    tempTrainScaled = scaler.fit_transform(tempTrain)\n",
    "    tempTestScaled = scaler.transform(tempTest)\n",
    "    \n",
    "    tModel = tuned_model[i].fit(tempTrainScaled, yTrain)\n",
    "    yPred = tModel.predict(tempTrainScaled)\n",
    "    \n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(yTrain, yPred).ravel()\n",
    "    \n",
    "    d = {'kernel' : kernelA[i],\n",
    "        'tn' : tn,\n",
    "        'fp' : fp,\n",
    "        'fn' : fn,\n",
    "        'tp' : tp,\n",
    "        'accuracy' : metrics.accuracy_score(yTrain, yPred)*100,\n",
    "        'precision' : metrics.precision_score(yTrain, yPred)*100,\n",
    "        'recall' : metrics.recall_score(yTrain, yPred)*100,\n",
    "        'f1' : metrics.f1_score(yTrain, yPred)*100}\n",
    "    \n",
    "    train_predict = train_predict.append(d, ignore_index=True)\n",
    "    \n",
    "    yPred = tModel.predict(tempTestScaled)\n",
    "    \n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(yTest, yPred).ravel()\n",
    "    \n",
    "    d = {'kernel' : kernelA[i],\n",
    "        'tn' : tn,\n",
    "        'fp' : fp,\n",
    "        'fn' : fn,\n",
    "        'tp' : tp,\n",
    "        'accuracy' : metrics.accuracy_score(yTest, yPred)*100,\n",
    "        'precision' : metrics.precision_score(yTest, yPred)*100,\n",
    "        'recall' : metrics.recall_score(yTest, yPred)*100,\n",
    "        'f1' : metrics.f1_score(yTest, yPred)*100}\n",
    "    \n",
    "    test_predict = test_predict.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>90.476190</td>\n",
       "      <td>81.250000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>89.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>79.365079</td>\n",
       "      <td>80.952381</td>\n",
       "      <td>65.384615</td>\n",
       "      <td>72.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  tn fp fn  tp    accuracy   precision      recall          f1\n",
       "0     rbf  31  6  0  26   90.476190   81.250000  100.000000   89.655172\n",
       "1  linear  33  4  9  17   79.365079   80.952381   65.384615   72.340426\n",
       "2    poly  37  0  0  26  100.000000  100.000000  100.000000  100.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>74.074074</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>37.037037</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>poly</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>35.714286</td>\n",
       "      <td>45.454545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel  tn fp  fn tp   accuracy  precision     recall         f1\n",
       "0     rbf  11  2   5  9  74.074074  81.818182  64.285714  72.000000\n",
       "1  linear   6  7  10  4  37.037037  36.363636  28.571429  32.000000\n",
       "2    poly  10  3   9  5  55.555556  62.500000  35.714286  45.454545"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c33f97e080>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "test_predict.plot()\n",
    "#plt.ylabel('Accuracy')\n",
    "#plt.xlabel('PCA Component Number')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_graph = pd.merge(train_predict.drop(['tn','fp','fn','tp'], axis=1), test_predict.drop(['tn','fp','fn','tp'], axis=1), on='kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transpose = bar_graph.T\n",
    "\n",
    "Transpose = Transpose.rename(columns=Transpose.iloc[0]).drop(Transpose.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Transpose.plot.bar()\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = train_predict.drop(['tn','fp','fn','tp'], axis=1).T.rename(columns=train_predict.drop(['tn','fp','fn','tp'], axis=1).T.iloc[0]).drop(train_predict.drop(['tn','fp','fn','tp'], axis=1).T.index[0])\n",
    "test_graph = test_predict.drop(['tn','fp','fn','tp'], axis=1).T.rename(columns=test_predict.drop(['tn','fp','fn','tp'], axis=1).T.iloc[0]).drop(test_predict.drop(['tn','fp','fn','tp'], axis=1).T.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "train_graph.plot.bar(ax=ax1)\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Train')\n",
    "ax1.set_xticklabels(train_graph.index, rotation=0)\n",
    "\n",
    "test_graph.plot.bar(ax=ax2)\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Test')\n",
    "ax2.set_xticklabels(test_graph.index, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only length-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-e1a8cf2a2ee8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.00\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'g'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1785\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2287\u001b[0m                 \u001b[0medgecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2288\u001b[0m                 \u001b[0mlinewidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2289\u001b[1;33m                 \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_nolegend_'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2290\u001b[0m                 )\n\u001b[0;32m   2291\u001b[0m             \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[0;32m    656\u001b[0m         \"\"\"\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[0mPatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_fill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_linestyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_linewidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_antialiased\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mantialiased\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_hatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kodok\\.conda\\envs\\TA\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mset_linewidth\u001b[1;34m(self, w)\u001b[0m\n\u001b[0;32m    346\u001b[0m                 \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'axes.linewidth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_linewidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;31m# scale the dash pattern by the linewidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_us_dashes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = [train_predict.iloc[:, 5:],\n",
    "test_predict.iloc[:, 5:]]\n",
    "X = np.arange(4)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(X + 0.00, data[0], color = 'b', width = 0.25)\n",
    "ax.bar(X + 0.25, data[1], color = 'g', width = 0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
